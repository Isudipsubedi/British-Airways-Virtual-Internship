{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "835835c3-23da-4d6e-9bbe-706c91df367a",
   "metadata": {},
   "source": [
    "**Web scraping and analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838ba4c7-153a-4816-862c-e4892cb38fb3",
   "metadata": {},
   "source": [
    "This Jupyter notebook includes some code to get you started with web scraping. We will use a package called BeautifulSoup to collect the data from the web. Once you've collected your data and saved it into a local .csv file you should start with your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063df066-6490-4af9-ae40-9ad3ed1ac04a",
   "metadata": {},
   "source": [
    "**Scraping data from Skytrax**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33291f1f-8e4f-4612-9626-c4e54678379d",
   "metadata": {},
   "source": [
    "If you visit [https://www.airlinequality.com] you can see that there is a lot of data there. For this task, we are only interested in reviews related to British Airways and the Airline itself.\n",
    "\n",
    "If you navigate to this link: [https://www.airlinequality.com/airline-reviews/british-airways] you will see this data. Now, we can use Python and BeautifulSoup to collect all the links to the reviews and then to collect the text data on each of the individual review links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fb8972e-937d-4e70-8b98-8a7350fc36f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7059d2d-8de6-4c9d-8b53-d0237a97a2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 100 total reviews\n",
      "Scraping page 2\n",
      "   ---> 200 total reviews\n",
      "Scraping page 3\n",
      "   ---> 300 total reviews\n",
      "Scraping page 4\n",
      "   ---> 400 total reviews\n",
      "Scraping page 5\n",
      "   ---> 500 total reviews\n",
      "Scraping page 6\n",
      "   ---> 600 total reviews\n",
      "Scraping page 7\n",
      "   ---> 700 total reviews\n",
      "Scraping page 8\n",
      "   ---> 800 total reviews\n",
      "Scraping page 9\n",
      "   ---> 900 total reviews\n",
      "Scraping page 10\n",
      "   ---> 1000 total reviews\n",
      "Scraping page 11\n",
      "   ---> 1100 total reviews\n",
      "Scraping page 12\n",
      "   ---> 1200 total reviews\n",
      "Scraping page 13\n",
      "   ---> 1300 total reviews\n",
      "Scraping page 14\n",
      "   ---> 1400 total reviews\n",
      "Scraping page 15\n",
      "   ---> 1500 total reviews\n",
      "Scraping page 16\n",
      "   ---> 1600 total reviews\n",
      "Scraping page 17\n",
      "   ---> 1700 total reviews\n",
      "Scraping page 18\n",
      "   ---> 1800 total reviews\n",
      "Scraping page 19\n",
      "   ---> 1900 total reviews\n",
      "Scraping page 20\n",
      "   ---> 2000 total reviews\n",
      "Scraping page 21\n",
      "   ---> 2100 total reviews\n",
      "Scraping page 22\n",
      "   ---> 2200 total reviews\n",
      "Scraping page 23\n",
      "   ---> 2300 total reviews\n",
      "Scraping page 24\n",
      "   ---> 2400 total reviews\n",
      "Scraping page 25\n",
      "   ---> 2500 total reviews\n",
      "Scraping page 26\n",
      "   ---> 2600 total reviews\n",
      "Scraping page 27\n",
      "   ---> 2700 total reviews\n",
      "Scraping page 28\n",
      "   ---> 2800 total reviews\n",
      "Scraping page 29\n",
      "   ---> 2900 total reviews\n",
      "Scraping page 30\n",
      "   ---> 3000 total reviews\n",
      "Scraping page 31\n",
      "   ---> 3100 total reviews\n",
      "Scraping page 32\n",
      "   ---> 3200 total reviews\n",
      "Scraping page 33\n",
      "   ---> 3300 total reviews\n",
      "Scraping page 34\n",
      "   ---> 3400 total reviews\n",
      "Scraping page 35\n",
      "   ---> 3500 total reviews\n",
      "Scraping page 36\n",
      "   ---> 3600 total reviews\n",
      "Scraping page 37\n",
      "   ---> 3700 total reviews\n",
      "Scraping page 38\n",
      "   ---> 3800 total reviews\n",
      "Scraping page 39\n",
      "   ---> 3900 total reviews\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "pages = 39\n",
    "page_size = 100\n",
    "\n",
    "reviews = []\n",
    "\n",
    "# for i in range(1, pages + 1):\n",
    "for i in range(1, pages + 1):\n",
    "\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse content\n",
    "    content = response.content\n",
    "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "    for para in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n",
    "        reviews.append(para.get_text())\n",
    "    \n",
    "    print(f\"   ---> {len(reviews)} total reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c24a0454-1218-4e88-b13f-308c5f8c3b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Verified |  An hour's delay due to late ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>✅ Trip Verified |   I booked through BA becaus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>✅ Trip Verified |   British airways lost bags ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>✅ Trip Verified | The check in process and rew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified |   We flew in November 2023, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews\n",
       "0  Not Verified |  An hour's delay due to late ar...\n",
       "1  ✅ Trip Verified |   I booked through BA becaus...\n",
       "2  ✅ Trip Verified |   British airways lost bags ...\n",
       "3  ✅ Trip Verified | The check in process and rew...\n",
       "4  ✅ Trip Verified |   We flew in November 2023, ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"reviews\"] = reviews\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296495b3-f743-45a1-b89a-a7dce7873d0f",
   "metadata": {},
   "source": [
    "Using the loops above, I collected 3900 reviews by iterating through the paginated pages on the website. If I want to gather even more data, I can increase the number of pages in the loop.\n",
    "\n",
    "The next step for me is to clean the data by removing any unnecessary text from each row. For example, phrases like \"✅ Trip Verified\" can be removed if they exist, as they aren’t relevant to the insights I want to investigate. By cleaning the dataset, I’ll ensure that I focus only on the essential content of each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fdd225d-3d46-4264-a6ab-07ef1b0ecf45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa935325-af8f-4b22-a706-13a5a2458119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Verified |  An hour's delay due to late ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>✅ Trip Verified |   I booked through BA becaus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>✅ Trip Verified |   British airways lost bags ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>✅ Trip Verified | The check in process and rew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified |   We flew in November 2023, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3895</th>\n",
       "      <td>Heathrow Marrakech. Had previously travelled o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3896</th>\n",
       "      <td>LHR-HKG on Boeing 747 - 23/08/12. Much has bee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3897</th>\n",
       "      <td>Just got back from Bridgetown Barbados flying ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3898</th>\n",
       "      <td>LHR-JFK-LAX-LHR. Check in was ok apart from be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>HKG-LHR in New Club World on Boeing 777-300 - ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3900 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                reviews\n",
       "0     Not Verified |  An hour's delay due to late ar...\n",
       "1     ✅ Trip Verified |   I booked through BA becaus...\n",
       "2     ✅ Trip Verified |   British airways lost bags ...\n",
       "3     ✅ Trip Verified | The check in process and rew...\n",
       "4     ✅ Trip Verified |   We flew in November 2023, ...\n",
       "...                                                 ...\n",
       "3895  Heathrow Marrakech. Had previously travelled o...\n",
       "3896  LHR-HKG on Boeing 747 - 23/08/12. Much has bee...\n",
       "3897  Just got back from Bridgetown Barbados flying ...\n",
       "3898  LHR-JFK-LAX-LHR. Check in was ok apart from be...\n",
       "3899  HKG-LHR in New Club World on Boeing 777-300 - ...\n",
       "\n",
       "[3900 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1155789-1231-4557-a2cf-ff7ce860583c",
   "metadata": {},
   "source": [
    "**Removing the parts before | in the reviews column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "279470a6-78de-4a6b-84e6-4fa4e4ea1496",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reviews= df.reviews.str.split('|',expand=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a6ab0e0-b58c-451e-a329-6c140992b7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An hour's delay due to late arrival of the i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I booked through BA because Loganair don’t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>British airways lost bags in LHR then found...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The check in process and reward/loyalty progr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We flew in November 2023, but it took this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3895</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3896</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3897</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3898</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3900 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                reviews\n",
       "0       An hour's delay due to late arrival of the i...\n",
       "1        I booked through BA because Loganair don’t ...\n",
       "2        British airways lost bags in LHR then found...\n",
       "3      The check in process and reward/loyalty progr...\n",
       "4        We flew in November 2023, but it took this ...\n",
       "...                                                 ...\n",
       "3895                                               None\n",
       "3896                                               None\n",
       "3897                                               None\n",
       "3898                                               None\n",
       "3899                                               None\n",
       "\n",
       "[3900 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485d0640-087f-437d-ab0e-6932e6f69348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
